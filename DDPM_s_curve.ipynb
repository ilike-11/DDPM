{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7a650e-a0e2-44cc-b789-35dadeddb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of s: (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_s_curve  # 生成S形二维数据点 https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "## ----------------------------- 1、生成数据，(10000, 2)的数据点集，组成一个S形 ----------------------------- ##\n",
    "s_curve, _ = make_s_curve(10 ** 4, noise=0.1)  # 生成10000个数据点，形状为S形并且带有噪声，shape为(10000,3)，形状是3维的\n",
    "s_curve = s_curve[:, [0, 2]] / 10.0 # 选择数据的第一列和第三列，并进行缩放\n",
    "print(\"shape of s:\", np.shape(s_curve))\n",
    "dataset = torch.Tensor(s_curve).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc747142-d776-41b5-8f12-c60845aeba6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------- 2、确定超参数的值 ----------------------------- ##\n",
    "# 采样时间步总长度 t\n",
    "num_steps = 100\n",
    " \n",
    "# 制定每一步的beta\n",
    "betas = torch.linspace(-6, 6, num_steps) # 在-6到6之间生成100个等间距的值\n",
    "betas = torch.sigmoid(betas) * (0.5e-2 - 1e-5) + 1e-5 # 将betas缩放到合适的范围\n",
    " \n",
    "# 计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值\n",
    "alphas = 1 - betas # 计算每一步的alpha值\n",
    "alphas_prod = torch.cumprod(alphas, 0) # 每个t时刻的alpha值的累积乘积\n",
    "# alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod) # 计算累积乘积的平方根\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod) # 计算1减去累积乘积的对数\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod) # 计算1减去累积乘积的平方根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5873a8-f8f6-4991-908e-31110cad1cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------- 3、确定扩散前向过程任意时刻的采样值 x[t]： x[0] + t --> x[t] ----------------------------- ##此代码并未使用这个\n",
    "def q_x(x_0, t):\n",
    "    \"\"\"\n",
    "    x[0] + t --> x[t]\n",
    "    :param x_0:初始数据\n",
    "    :param t:任意时刻\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    noise = torch.randn_like(x_0)\n",
    "    alphas_t = alphas_bar_sqrt[t]\n",
    "    alphas_1_m_t = one_minus_alphas_bar_sqrt[t]\n",
    "    x_t = alphas_t * x_0 + alphas_1_m_t * noise\n",
    "    return x_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d53d9809-6453-4206-b683-420de18d7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------- 4、编写求逆扩散过程噪声的模型U-Net（这里使用的是MLP模拟U-Net，官方使用的是U-Net） x[t] + t --> noise_predict----------------------------- ##预测噪声\n",
    "class MLPDiffusion(nn.Module):\n",
    "    def __init__(self, n_steps, num_units=128):\n",
    "        super(MLPDiffusion, self).__init__()\n",
    " \n",
    "        self.linears = nn.ModuleList(\n",
    "            [\n",
    "                nn.Linear(2, num_units),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_units, num_units),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_units, num_units),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_units, 2),\n",
    "            ]\n",
    "        )\n",
    "        self.step_embeddings = nn.ModuleList(\n",
    "            [\n",
    "                nn.Embedding(n_steps, num_units),\n",
    "                nn.Embedding(n_steps, num_units),\n",
    "                nn.Embedding(n_steps, num_units),\n",
    "            ]\n",
    "        )\n",
    " \n",
    "    def forward(self, x, t):\n",
    "        #  x = x[0]\n",
    "        for idx, embedding_layer in enumerate(self.step_embeddings):\n",
    "            t_embedding = embedding_layer(t)\n",
    "            x = self.linears[2 * idx](x)\n",
    "            x += t_embedding\n",
    "            x = self.linears[2 * idx + 1](x)\n",
    "        x = self.linears[-1](x)\n",
    " \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6010bb30-b75e-4fae-9a40-0b0ad3347967",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------- 损失函数 = 真实噪声eps与预测出的噪声noise_predict 之间的loss ----------------------------- ##\n",
    "def diffusion_loss_fn(model, x_0, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, n_steps):\n",
    "    \"\"\"对任意时刻t进行采样计算loss\"\"\"\n",
    "    batch_size = x_0.shape[0]\n",
    " \n",
    "    # 对一个batchsize样本生成随机的时刻t, t的形状是torch.Size([batchsize, 1])\n",
    "    t = torch.randint(0, n_steps, size=(batch_size // 2,)) # 随机生成时间步t，一半时间\n",
    "    t = torch.cat([t, n_steps - 1 - t], dim=0) # 创建对称的时间步\n",
    "    t = t.unsqueeze(-1) # 添加一个维度，使t的形状为(batch_size, 1)\n",
    " \n",
    "    ## 1) 根据 alphas_bar_sqrt, one_minus_alphas_bar_sqrt --> 得到任意时刻t的采样值x[t]\n",
    "    # x0的系数\n",
    "    a = alphas_bar_sqrt[t] # 获取时间步t对应的alphas_bar_sqrt值\n",
    "    # 噪声eps的系数\n",
    "    aml = one_minus_alphas_bar_sqrt[t] # 获取时间步t对应的one_minus_alphas_bar_sqrt值\n",
    "    # 生成生成与x_0形状相同的随机噪声e\n",
    "    e = torch.randn_like(x_0)\n",
    "    # 计算任意时刻t的采样值\n",
    "    x = x_0 * a + e * aml\n",
    " \n",
    "    ## 2) x[t]送入U-Net模型，得到t时刻的随机噪声预测值，这里是用UNet直接预测噪声，输入网络的参数是加上噪声的图像和时间t，网络返回预测所加的噪声\n",
    "    output = model(x, t.squeeze(-1))\n",
    " \n",
    "    ## 3)计算真实噪声eps与预测出的噪声之间的loss\n",
    "    loss = (e - output).square().mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2809e0e-9720-4465-88ec-5743335f0c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:   0%|                                                                   | 1/4000 [00:00<26:15,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6277, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:   3%|█▋                                                               | 101/4000 [00:50<33:59,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7523, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:   5%|███▎                                                             | 201/4000 [01:45<40:31,  1.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8193, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:   8%|████▉                                                            | 301/4000 [02:36<24:34,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4371, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  10%|██████▌                                                          | 401/4000 [03:17<23:39,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2920, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  13%|████████▏                                                        | 501/4000 [03:56<22:51,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4311, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  15%|█████████▊                                                       | 601/4000 [04:35<22:17,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3186, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  18%|███████████▍                                                     | 701/4000 [05:14<21:37,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4662, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  20%|█████████████                                                    | 801/4000 [05:54<21:24,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2823, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  23%|██████████████▋                                                  | 901/4000 [06:34<21:05,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3782, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  25%|████████████████                                                | 1001/4000 [07:20<18:50,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3412, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  28%|█████████████████▌                                              | 1101/4000 [07:58<18:34,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2555, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  30%|███████████████████▏                                            | 1201/4000 [08:37<19:01,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3031, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  33%|████████████████████▊                                           | 1301/4000 [09:18<18:39,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2732, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  35%|██████████████████████▍                                         | 1401/4000 [09:59<17:45,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3399, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  38%|████████████████████████                                        | 1501/4000 [10:40<17:26,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2077, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  40%|█████████████████████████▌                                      | 1601/4000 [11:22<16:43,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3160, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  43%|███████████████████████████▏                                    | 1701/4000 [12:04<16:08,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3021, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  45%|████████████████████████████▊                                   | 1801/4000 [12:45<15:06,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2696, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  48%|██████████████████████████████▍                                 | 1901/4000 [13:27<14:26,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5254, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  50%|████████████████████████████████                                | 2001/4000 [14:08<13:40,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2974, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  53%|█████████████████████████████████▌                              | 2101/4000 [14:50<12:56,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2059, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  55%|███████████████████████████████████▏                            | 2201/4000 [15:31<12:27,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4414, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  58%|████████████████████████████████████▊                           | 2301/4000 [16:13<11:45,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7000, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  60%|██████████████████████████████████████▍                         | 2401/4000 [16:55<10:57,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2715, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  63%|████████████████████████████████████████                        | 2501/4000 [17:37<10:28,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2859, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  65%|█████████████████████████████████████████▌                      | 2601/4000 [18:21<10:09,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2143, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  68%|███████████████████████████████████████████▏                    | 2701/4000 [19:03<09:13,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3457, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  70%|████████████████████████████████████████████▊                   | 2801/4000 [19:45<08:32,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2908, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  73%|██████████████████████████████████████████████▍                 | 2901/4000 [20:28<07:49,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2334, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  75%|████████████████████████████████████████████████                | 3001/4000 [21:11<07:56,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3302, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  78%|█████████████████████████████████████████████████▌              | 3101/4000 [22:02<05:56,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3580, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  80%|███████████████████████████████████████████████████▏            | 3201/4000 [22:43<05:30,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2557, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  83%|████████████████████████████████████████████████████▊           | 3301/4000 [23:24<05:05,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1737, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  85%|██████████████████████████████████████████████████████▍         | 3401/4000 [24:08<04:13,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1599, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  88%|████████████████████████████████████████████████████████        | 3501/4000 [24:52<03:36,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5057, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  90%|█████████████████████████████████████████████████████████▌      | 3601/4000 [25:36<02:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4080, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  93%|███████████████████████████████████████████████████████████▏    | 3701/4000 [26:18<02:05,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6685, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  95%|████████████████████████████████████████████████████████████▊   | 3801/4000 [27:02<01:21,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3077, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch:  98%|██████████████████████████████████████████████████████████████▍ | 3901/4000 [27:46<00:41,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2923, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traing epoch: 100%|████████████████████████████████████████████████████████████████| 4000/4000 [28:30<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "## ----------------------------- 训练模型 ----------------------------- ##\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print('Training model...')\n",
    "    batch_size = 128\n",
    "    num_epoch = 4000\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    model = MLPDiffusion(num_steps)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for t in tqdm(range(num_epoch),desc=\"Traing epoch\"):\n",
    "        for idx, batch_x in enumerate(dataloader):\n",
    "            loss = diffusion_loss_fn(model, batch_x, alphas_bar_sqrt, one_minus_alphas_bar_sqrt, num_steps)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.)\n",
    "            optimizer.step()\n",
    "    \n",
    "        if (t % 100 == 0):\n",
    "            print(loss)\n",
    "            torch.save(model.state_dict(), 'model_{}.pth'.format(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59b352a5-c3f8-4934-a45a-8a30885f001c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of s: (10000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\honor\\AppData\\Local\\Temp\\ipykernel_22012\\1356329506.py:77: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./checkpoints_cpu/model_3900.pth'))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints_cpu/model_3900.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# 1) 加载训练好的diffusion model\u001b[39;00m\n\u001b[0;32m     76\u001b[0m model \u001b[38;5;241m=\u001b[39m MLPDiffusion(num_steps)\n\u001b[1;32m---> 77\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints_cpu/model_3900.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# 2) 生成随机噪声x[T]\u001b[39;00m\n\u001b[0;32m     80\u001b[0m noise_x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(dataset\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mE:\\Anaconda\\conda\\Lib\\site-packages\\torch\\serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mE:\\Anaconda\\conda\\Lib\\site-packages\\torch\\serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mE:\\Anaconda\\conda\\Lib\\site-packages\\torch\\serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints_cpu/model_3900.pth'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_s_curve  # 生成S形二维数据点 https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_s_curve.html\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from train import MLPDiffusion\n",
    "\n",
    "\n",
    "\n",
    "## ----------------------------- 1、生成数据，(10000, 2)的数据点集，组成一个S形 ----------------------------- ##\n",
    "s_curve, _ = make_s_curve(10 ** 4, noise=0.1)  # 10000个数据点\n",
    "s_curve = s_curve[:, [0, 2]] / 10.0\n",
    "print(\"shape of s:\", np.shape(s_curve))\n",
    "dataset = torch.Tensor(s_curve).float()\n",
    "\n",
    "## ----------------------------- 2、确定超参数的值 ----------------------------- ##\n",
    "# 采样时间步总长度 t\n",
    "num_steps = 100\n",
    " \n",
    "# 制定每一步的beta\n",
    "betas = torch.linspace(-6, 6, num_steps)\n",
    "betas = torch.sigmoid(betas) * (0.5e-2 - 1e-5) + 1e-5\n",
    " \n",
    "# 计算alpha、alpha_prod、alpha_prod_previous、alpha_bar_sqrt等变量的值\n",
    "alphas = 1 - betas\n",
    "alphas_prod = torch.cumprod(alphas, 0)\n",
    "alphas_prod_p = torch.cat([torch.tensor([1]).float(), alphas_prod[:-1]], 0)\n",
    "alphas_bar_sqrt = torch.sqrt(alphas_prod)\n",
    "one_minus_alphas_bar_log = torch.log(1 - alphas_prod)\n",
    "one_minus_alphas_bar_sqrt = torch.sqrt(1 - alphas_prod)\n",
    "\n",
    "\n",
    "def p_sample(model, x, t, betas, one_minus_alphas_bar_sqrt):\n",
    "    \"\"\"\n",
    "    从x[t]采样t-1时刻的重构值x[t-1]，根据论文中的采样公式计算单步的采样\n",
    "    :param model:\n",
    "    :param x: x[T]\n",
    "    :param t:\n",
    "    :param betas:\n",
    "    :param one_minus_alphas_bar_sqrt:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    ## 1) 求出 bar_u_t\n",
    "    t = torch.tensor([t])\n",
    "    coeff = betas[t] / one_minus_alphas_bar_sqrt[t] # 这里先计算采样公式中的一部分参数，方便后面表示，看不懂的可以直接对着论文公式看\n",
    "    # 送入U-Net模型，得到t时刻的随机噪声预测值 eps_theta\n",
    "    eps_theta = model(x, t)\n",
    "    mean = (1 / (1 - betas[t]).sqrt()) * (x - (coeff * eps_theta))\n",
    " \n",
    "    ## 2) 得到 x[t-1]\n",
    "    z = torch.randn_like(x)\n",
    "    sigma_t = betas[t].sqrt()\n",
    "    sample = mean + sigma_t * z\n",
    "    return sample\n",
    "\n",
    "def p_sample_loop(model, noise_x_t, n_steps, betas, one_minus_alphas_bar_sqrt):\n",
    "    \"\"\"\n",
    "    从x[T]恢复x[T-1]、x[T-2]|...x[0] 的循环\n",
    "    :param model:\n",
    "    :param shape:数据集的形状，也就是x[T]的形状\n",
    "    :param n_steps:\n",
    "    :param betas:\n",
    "    :param one_minus_alphas_bar_sqrt:\n",
    "    :return: x_seq由x[T]、x[T-1]、x[T-2]|...x[0]组成, cur_x是从噪声中生成的图片\n",
    "    \"\"\"\n",
    "    # 得到噪声x[T]\n",
    "    cur_x = noise_x_t # 初始化当前的x为噪声x[T]\n",
    "    x_seq = [noise_x_t] # 初始化x序列为第一个元素为x[T],也就是纯噪声\n",
    "    # 从x[T]恢复x[T-1]、x[T-2]|...x[0]\n",
    "    for i in reversed(range(n_steps)):\n",
    "        cur_x = p_sample(model, cur_x, i, betas, one_minus_alphas_bar_sqrt)\n",
    "        x_seq.append(cur_x)\n",
    "    return x_seq, cur_x\n",
    "\n",
    "# 1) 加载训练好的diffusion model\n",
    "model = MLPDiffusion(num_steps)\n",
    "model.load_state_dict(torch.load('./checkpoints_cpu/model_3900.pth'))\n",
    "\n",
    "# 2) 生成随机噪声x[T]\n",
    "noise_x_t = torch.randn(dataset.shape)\n",
    "\n",
    "# 3) 根据随机噪声逆扩散为x[T-1]、x[T-2]|...x[0] + 图片x[0]\n",
    "x_seq, cur_x = p_sample_loop(model, noise_x_t, num_steps, betas, one_minus_alphas_bar_sqrt)\n",
    "\n",
    "# 4) 绘制并保存图像\n",
    "def plot_samples(x_seq, cur_x):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # 绘制 x_seq\n",
    "    for i, x in enumerate(x_seq):\n",
    "        if i % 10 == 0:  # 每10个时间步绘制一次\n",
    "            ax[0].scatter(x.detach().numpy()[:, 0], x.detach().numpy()[:, 1], label=f'Step {i}', alpha=0.5)\n",
    "    ax[0].legend()\n",
    "    ax[0].set_title('x_seq')\n",
    "    \n",
    "    # 绘制 cur_x\n",
    "    ax[1].scatter(cur_x.detach().numpy()[:, 0], cur_x.detach().numpy()[:, 1], color='red')\n",
    "    ax[1].set_title('cur_x')\n",
    "    \n",
    "    plt.savefig('samples_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(x_seq, cur_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b319f561-97cc-4ff7-88fa-8ee5eec425cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97db093-9027-43d0-a6c2-b7b606c5fbfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b6dbf-ae48-4649-b397-06eb09d007c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
